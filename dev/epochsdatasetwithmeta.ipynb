{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, os.path.realpath(os.path.pardir))\n",
    "from deepmeg.data.datasets import EpochsDataset, EpochsDatasetWithMeta\n",
    "import numpy as np\n",
    "from typing import Callable, Any\n",
    "import torch\n",
    "import mne\n",
    "from deepmeg.preprocessing.transforms import one_hot_encoder\n",
    "from deepmeg.utils import check_path\n",
    "from collections.abc import Iterable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening raw data file /home/user/mne_data/MNE-multimodal-data/multimodal_raw.fif...\n",
      "    Read a total of 7 projection items:\n",
      "        grad_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        grad_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v1 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v2 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v3 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v4 (1 x 306)  idle\n",
      "        mag_ssp_upright.fif : PCA-v5 (1 x 306)  idle\n",
      "    Range : 183600 ... 576599 =    305.687 ...   960.014 secs\n",
      "Ready.\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Not setting metadata\n",
      "129 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Not setting metadata\n",
      "115 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Not setting metadata\n",
      "133 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Not setting metadata\n",
      "107 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Not setting metadata\n",
      "118 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Not setting metadata\n",
      "104 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Not setting metadata\n",
      "117 matching events found\n",
      "Setting baseline interval to [-0.09989760657919393, 0.0] sec\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n",
      "7 projection items activated\n",
      "Loading data for 118 events and 361 original time points ...\n",
      "1 bad epochs dropped\n",
      "Loading data for 129 events and 361 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 115 events and 361 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 133 events and 361 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 107 events and 361 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 118 events and 361 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 104 events and 361 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 117 events and 361 original time points ...\n",
      "0 bad epochs dropped\n",
      "Loading data for 117 events and 361 original time points ...\n",
      "Loading data for 129 events and 361 original time points ...\n",
      "Loading data for 115 events and 361 original time points ...\n",
      "Loading data for 133 events and 361 original time points ...\n",
      "Loading data for 107 events and 361 original time points ...\n",
      "Loading data for 118 events and 361 original time points ...\n",
      "Loading data for 104 events and 361 original time points ...\n",
      "Loading data for 117 events and 361 original time points ...\n",
      "Not setting metadata\n",
      "940 matching events found\n",
      "Applying baseline correction (mode: mean)\n",
      "Created an SSP operator (subspace dimension = 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Number of events</th>\n",
       "        <td>940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Events</th>\n",
       "        \n",
       "        <td>Auditory left: 117<br/>Auditory right: 104<br/>Somato left: 118<br/>Somato right: 107<br/>Visual Lower left: 115<br/>Visual Lower right: 129<br/>Visual Upper left: 133<br/>Visual Upper right: 117</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Time range</th>\n",
       "        <td>-0.100 – 0.499 sec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Baseline</th>\n",
       "        <td>-0.100 – 0.000 sec</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<EpochsArray |  940 events (all good), -0.0998976 - 0.499488 sec, baseline -0.0998976 – 0 sec, ~531.4 MB, data loaded,\n",
       " 'Visual Upper right': 117\n",
       " 'Visual Lower right': 129\n",
       " 'Visual Lower left': 115\n",
       " 'Visual Upper left': 133\n",
       " 'Somato right': 107\n",
       " 'Somato left': 118\n",
       " 'Auditory right': 104\n",
       " 'Auditory left': 117>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mne.datasets import multimodal\n",
    "fname_raw = os.path.join(multimodal.data_path(), 'multimodal_raw.fif')\n",
    "raw = mne.io.read_raw_fif(fname_raw)\n",
    "\n",
    "cond = raw.acqparser.get_condition(raw, None)\n",
    "condition_names = [k for c in cond for k,v in c['event_id'].items()]\n",
    "epochs_list = [mne.Epochs(raw, **c) for c in cond]\n",
    "epochs = mne.concatenate_epochs(epochs_list)\n",
    "epochs.pick_types(meg='grad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "940"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding metadata with 5 columns\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "epochs.metadata = pd.DataFrame(np.concatenate([np.random.random((len(epochs), 4)), np.expand_dims(np.arange(len(epochs)), -1)], axis=-1), columns = ['col 1', 'col 2', 'col 3', 'col 4', 'order'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "class EpochsDatasetWithMeta(EpochsDataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        epochs: str | os.PathLike | tuple[np.ndarray, np.ndarray] | tuple[np.ndarray, np.ndarray, Iterable] | mne.Epochs,\n",
    "        transform: Callable[[torch.Tensor], torch.Tensor] = None, target_transform: Callable[[torch.Tensor], torch.Tensor]  = None,\n",
    "        savepath: str | os.PathLike = './data'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A PyTorch dataset class for EEG data with additional metadata.\n",
    "\n",
    "        Args:\n",
    "            epochs: An instance of mne.Epochs or a tuple of EEG data X and target Y with optional metadata Z, or a file path to load mne.Epochs data.\n",
    "            transform: A callable function to apply a transformation on the input data.\n",
    "            target_transform: A callable function to apply a transformation on the target data.\n",
    "            savepath: A path to the directory to save the processed data.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: If the data type for samples is not supported.\n",
    "\n",
    "        Attributes:\n",
    "            n_samples: An integer representing the total number of data samples.\n",
    "            savepath: A path to the directory to save the processed data.\n",
    "            transform: A callable function to apply a transformation on the input data.\n",
    "            target_transform: A callable function to apply a transformation on the target data.\n",
    "        \"\"\"\n",
    "        if isinstance(epochs, (str, os.PathLike)):\n",
    "            epochs = mne.read_epochs(epochs)\n",
    "\n",
    "        if isinstance(epochs, (mne.Epochs, mne.epochs.EpochsArray)):\n",
    "            data = epochs.get_data()\n",
    "            X = [torch.Tensor(sample) for sample in data]\n",
    "            Y = one_hot_encoder(epochs.events[:, 2])\n",
    "            Y = [torch.Tensor(event) for event in Y]\n",
    "            Z = list(epochs.metadata.iterrows()) if epochs.metadata is not None else [None for _ in range(len(X))]\n",
    "        elif isinstance(epochs, tuple):\n",
    "            X = [torch.Tensor(sample) for sample in epochs[0]]\n",
    "            Y = [torch.Tensor(target) for target in epochs[1]]\n",
    "\n",
    "            if len(epochs) == 3:\n",
    "                Z = [metadata for metadata in epochs[2]]\n",
    "            else:\n",
    "                Z = [None for _ in range(len(X))]\n",
    "        else:\n",
    "            raise ValueError(f'Unsupported type for data samples: {type(epochs)}')\n",
    "\n",
    "        self.n_samples = len(X)\n",
    "        self.savepath = savepath\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "\n",
    "        check_path(savepath)\n",
    "\n",
    "        for i, (sample, target, meta) in enumerate(zip(X, Y, Z)):\n",
    "            torch.save(sample, os.path.join(self.savepath, f'sample_{i}.pt'))\n",
    "            torch.save(target, os.path.join(self.savepath, f'target_{i}.pt'))\n",
    "\n",
    "            if meta is not None:\n",
    "                torch.save(meta, os.path.join(self.savepath, f'meta_{i}.pt'))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a processed data sample and its target with optional metadata from the dataset.\n",
    "\n",
    "        Args:\n",
    "            idx: An integer representing the index of the data sample.\n",
    "\n",
    "        Returns:\n",
    "            X: A PyTorch Tensor representing the processed input data sample.\n",
    "            Y: A PyTorch Tensor representing the processed target data.\n",
    "            Z: A PyTorch Tensor representing the metadata, or None if not available.\n",
    "\n",
    "        \"\"\"\n",
    "        sample_path = os.path.join(self.savepath, f'sample_{idx}.pt')\n",
    "        target_path = os.path.join(self.savepath, f'target_{idx}.pt')\n",
    "        meta_path = os.path.join(self.savepath, f'meta_{idx}.pt')\n",
    "\n",
    "        X = torch.load(sample_path)\n",
    "        Y = torch.load(target_path)\n",
    "        Z = torch.load(meta_path) if os.path.exists(meta_path) else None\n",
    "\n",
    "        if self.transform:\n",
    "            X = self.transform(X)\n",
    "\n",
    "        if self.target_transform:\n",
    "            Y = self.target_transform(Y)\n",
    "\n",
    "        return X, Y, Z\n",
    "\n",
    "    def to_epochsdataset(self, inplace: bool = False):\n",
    "        \"\"\"Converts the EpochsDatasetWithMeta object to EpochsDataset\"\"\"\n",
    "        if not inplace:\n",
    "            new_dataset = deepcopy(self)\n",
    "        else:\n",
    "            new_dataset = self\n",
    "\n",
    "        new_dataset.__getitem__ = super().__getitem__\n",
    "\n",
    "        return new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EpochsDataset(epochs, savepath='../datasets/with_meta')\n",
    "dataset.save('../data/no_meta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method EpochsDataset.__getitem__ of <__main__.EpochsDatasetWithMeta object at 0x7f37a7e05660>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0,\n",
       " col 1    0.670604\n",
       " col 2    0.161635\n",
       " col 3    0.585807\n",
       " col 4    0.245524\n",
       " order    0.000000\n",
       " Name: 0, dtype: float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.to_epochsdataset()[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, z = dataset[1, 'all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator1 = torch.Generator().manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = EpochsDataset.load('../data/with_meta.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0][-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = torch.utils.data.random_split(dataset, [.7, .3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[295,\n",
       " 936,\n",
       " 141,\n",
       " 255,\n",
       " 399,\n",
       " 216,\n",
       " 611,\n",
       " 201,\n",
       " 890,\n",
       " 799,\n",
       " 137,\n",
       " 26,\n",
       " 121,\n",
       " 467,\n",
       " 826,\n",
       " 573,\n",
       " 328,\n",
       " 98,\n",
       " 490,\n",
       " 179,\n",
       " 456,\n",
       " 693,\n",
       " 352,\n",
       " 692,\n",
       " 558,\n",
       " 419,\n",
       " 652,\n",
       " 92,\n",
       " 254,\n",
       " 327,\n",
       " 105,\n",
       " 333,\n",
       " 165,\n",
       " 502,\n",
       " 631,\n",
       " 522,\n",
       " 318,\n",
       " 67,\n",
       " 551,\n",
       " 190,\n",
       " 804,\n",
       " 316,\n",
       " 87,\n",
       " 734,\n",
       " 738,\n",
       " 43,\n",
       " 73,\n",
       " 816,\n",
       " 129,\n",
       " 286,\n",
       " 336,\n",
       " 274,\n",
       " 762,\n",
       " 684,\n",
       " 745,\n",
       " 431,\n",
       " 276,\n",
       " 740,\n",
       " 460,\n",
       " 831,\n",
       " 305,\n",
       " 884,\n",
       " 4,\n",
       " 820,\n",
       " 928,\n",
       " 517,\n",
       " 7,\n",
       " 6,\n",
       " 657,\n",
       " 570,\n",
       " 607,\n",
       " 838,\n",
       " 96,\n",
       " 46,\n",
       " 603,\n",
       " 257,\n",
       " 867,\n",
       " 743,\n",
       " 492,\n",
       " 264,\n",
       " 575,\n",
       " 939,\n",
       " 662,\n",
       " 595,\n",
       " 780,\n",
       " 432,\n",
       " 200,\n",
       " 309,\n",
       " 642,\n",
       " 906,\n",
       " 387,\n",
       " 150,\n",
       " 773,\n",
       " 774,\n",
       " 920,\n",
       " 567,\n",
       " 430,\n",
       " 843,\n",
       " 149,\n",
       " 335,\n",
       " 747,\n",
       " 119,\n",
       " 823,\n",
       " 829,\n",
       " 615,\n",
       " 463,\n",
       " 132,\n",
       " 610,\n",
       " 471,\n",
       " 415,\n",
       " 65,\n",
       " 759,\n",
       " 11,\n",
       " 80,\n",
       " 291,\n",
       " 926,\n",
       " 453,\n",
       " 358,\n",
       " 550,\n",
       " 355,\n",
       " 937,\n",
       " 154,\n",
       " 41,\n",
       " 433,\n",
       " 521,\n",
       " 185,\n",
       " 422,\n",
       " 30,\n",
       " 851,\n",
       " 722,\n",
       " 242,\n",
       " 718,\n",
       " 14,\n",
       " 446,\n",
       " 401,\n",
       " 360,\n",
       " 449,\n",
       " 687,\n",
       " 624,\n",
       " 576,\n",
       " 193,\n",
       " 485,\n",
       " 458,\n",
       " 22,\n",
       " 347,\n",
       " 832,\n",
       " 223,\n",
       " 591,\n",
       " 833,\n",
       " 908,\n",
       " 340,\n",
       " 751,\n",
       " 393,\n",
       " 385,\n",
       " 19,\n",
       " 36,\n",
       " 396,\n",
       " 881,\n",
       " 125,\n",
       " 685,\n",
       " 406,\n",
       " 103,\n",
       " 915,\n",
       " 473,\n",
       " 435,\n",
       " 571,\n",
       " 643,\n",
       " 754,\n",
       " 371,\n",
       " 204,\n",
       " 903,\n",
       " 574,\n",
       " 464,\n",
       " 715,\n",
       " 161,\n",
       " 82,\n",
       " 249,\n",
       " 437,\n",
       " 768,\n",
       " 361,\n",
       " 898,\n",
       " 343,\n",
       " 556,\n",
       " 226,\n",
       " 824,\n",
       " 725,\n",
       " 0,\n",
       " 172,\n",
       " 709,\n",
       " 258,\n",
       " 505,\n",
       " 174,\n",
       " 821,\n",
       " 531,\n",
       " 57,\n",
       " 894,\n",
       " 791,\n",
       " 661,\n",
       " 862,\n",
       " 66,\n",
       " 62,\n",
       " 55,\n",
       " 494,\n",
       " 102,\n",
       " 448,\n",
       " 582,\n",
       " 700,\n",
       " 781,\n",
       " 164,\n",
       " 750,\n",
       " 184,\n",
       " 289,\n",
       " 493,\n",
       " 589,\n",
       " 114,\n",
       " 56,\n",
       " 540,\n",
       " 194,\n",
       " 864,\n",
       " 133,\n",
       " 476,\n",
       " 612,\n",
       " 523,\n",
       " 314,\n",
       " 470,\n",
       " 52,\n",
       " 349,\n",
       " 450,\n",
       " 721,\n",
       " 600,\n",
       " 848,\n",
       " 766,\n",
       " 300,\n",
       " 202,\n",
       " 658,\n",
       " 637,\n",
       " 807,\n",
       " 510,\n",
       " 126,\n",
       " 499,\n",
       " 178,\n",
       " 68,\n",
       " 428,\n",
       " 796,\n",
       " 897,\n",
       " 34,\n",
       " 909,\n",
       " 760,\n",
       " 47,\n",
       " 840,\n",
       " 86,\n",
       " 332,\n",
       " 479,\n",
       " 110,\n",
       " 896,\n",
       " 749,\n",
       " 162,\n",
       " 317,\n",
       " 123,\n",
       " 359,\n",
       " 342,\n",
       " 858,\n",
       " 294,\n",
       " 329,\n",
       " 837,\n",
       " 248,\n",
       " 664,\n",
       " 366,\n",
       " 712,\n",
       " 681,\n",
       " 293,\n",
       " 195,\n",
       " 380,\n",
       " 405,\n",
       " 728,\n",
       " 868,\n",
       " 106,\n",
       " 511,\n",
       " 219,\n",
       " 886,\n",
       " 268,\n",
       " 207,\n",
       " 290,\n",
       " 262,\n",
       " 850,\n",
       " 496,\n",
       " 883,\n",
       " 61,\n",
       " 911,\n",
       " 680,\n",
       " 666,\n",
       " 546,\n",
       " 679,\n",
       " 622,\n",
       " 770,\n",
       " 397,\n",
       " 655,\n",
       " 18,\n",
       " 727,\n",
       " 163,\n",
       " 10,\n",
       " 737,\n",
       " 645,\n",
       " 507,\n",
       " 549,\n",
       " 198,\n",
       " 391,\n",
       " 344,\n",
       " 625,\n",
       " 918,\n",
       " 767,\n",
       " 250,\n",
       " 811,\n",
       " 363,\n",
       " 841,\n",
       " 640,\n",
       " 220,\n",
       " 191,\n",
       " 588,\n",
       " 234,\n",
       " 498,\n",
       " 145,\n",
       " 912,\n",
       " 442,\n",
       " 228,\n",
       " 618,\n",
       " 187,\n",
       " 153,\n",
       " 782,\n",
       " 696,\n",
       " 548,\n",
       " 416,\n",
       " 205,\n",
       " 260,\n",
       " 321,\n",
       " 85,\n",
       " 72,\n",
       " 854,\n",
       " 377,\n",
       " 905,\n",
       " 808,\n",
       " 581,\n",
       " 443,\n",
       " 222,\n",
       " 480,\n",
       " 675,\n",
       " 345,\n",
       " 373,\n",
       " 885,\n",
       " 16,\n",
       " 214,\n",
       " 383,\n",
       " 447,\n",
       " 802,\n",
       " 451,\n",
       " 555,\n",
       " 847,\n",
       " 111,\n",
       " 181,\n",
       " 665,\n",
       " 5,\n",
       " 753,\n",
       " 372,\n",
       " 812,\n",
       " 594,\n",
       " 384,\n",
       " 938,\n",
       " 120,\n",
       " 32,\n",
       " 553,\n",
       " 115,\n",
       " 350,\n",
       " 91,\n",
       " 752,\n",
       " 364,\n",
       " 283,\n",
       " 50,\n",
       " 395,\n",
       " 717,\n",
       " 748,\n",
       " 307,\n",
       " 708,\n",
       " 251,\n",
       " 320,\n",
       " 830,\n",
       " 402,\n",
       " 707,\n",
       " 524,\n",
       " 322,\n",
       " 663,\n",
       " 922,\n",
       " 557,\n",
       " 424,\n",
       " 537,\n",
       " 529,\n",
       " 410,\n",
       " 338,\n",
       " 365,\n",
       " 469,\n",
       " 180,\n",
       " 244,\n",
       " 585,\n",
       " 339,\n",
       " 407,\n",
       " 598,\n",
       " 139,\n",
       " 805,\n",
       " 158,\n",
       " 873,\n",
       " 879,\n",
       " 418,\n",
       " 599,\n",
       " 632,\n",
       " 302,\n",
       " 878,\n",
       " 388,\n",
       " 44,\n",
       " 24,\n",
       " 907,\n",
       " 849,\n",
       " 584,\n",
       " 703,\n",
       " 617,\n",
       " 538,\n",
       " 561,\n",
       " 381,\n",
       " 694,\n",
       " 518,\n",
       " 491,\n",
       " 835,\n",
       " 131,\n",
       " 414,\n",
       " 99,\n",
       " 863,\n",
       " 292,\n",
       " 704,\n",
       " 853,\n",
       " 789,\n",
       " 794,\n",
       " 176,\n",
       " 315,\n",
       " 689,\n",
       " 742,\n",
       " 723,\n",
       " 31,\n",
       " 690,\n",
       " 398,\n",
       " 923,\n",
       " 545,\n",
       " 934,\n",
       " 53,\n",
       " 827,\n",
       " 256,\n",
       " 756,\n",
       " 160,\n",
       " 138,\n",
       " 29,\n",
       " 434,\n",
       " 726,\n",
       " 379,\n",
       " 788,\n",
       " 635,\n",
       " 899,\n",
       " 440,\n",
       " 683,\n",
       " 876,\n",
       " 653,\n",
       " 515,\n",
       " 702,\n",
       " 860,\n",
       " 777,\n",
       " 146,\n",
       " 711,\n",
       " 376,\n",
       " 895,\n",
       " 182,\n",
       " 698,\n",
       " 152,\n",
       " 534,\n",
       " 646,\n",
       " 238,\n",
       " 764,\n",
       " 579,\n",
       " 408,\n",
       " 370,\n",
       " 9,\n",
       " 636,\n",
       " 159,\n",
       " 90,\n",
       " 167,\n",
       " 790,\n",
       " 20,\n",
       " 64,\n",
       " 95,\n",
       " 130,\n",
       " 375,\n",
       " 27,\n",
       " 593,\n",
       " 814,\n",
       " 230,\n",
       " 757,\n",
       " 769,\n",
       " 271,\n",
       " 168,\n",
       " 845,\n",
       " 931,\n",
       " 865,\n",
       " 420,\n",
       " 929,\n",
       " 798,\n",
       " 559,\n",
       " 578,\n",
       " 390,\n",
       " 421,\n",
       " 71,\n",
       " 606,\n",
       " 48,\n",
       " 724,\n",
       " 331,\n",
       " 803,\n",
       " 394,\n",
       " 917,\n",
       " 472,\n",
       " 822,\n",
       " 75,\n",
       " 544,\n",
       " 776,\n",
       " 609,\n",
       " 674,\n",
       " 33,\n",
       " 301,\n",
       " 659,\n",
       " 444,\n",
       " 525,\n",
       " 761,\n",
       " 797,\n",
       " 638,\n",
       " 716,\n",
       " 445,\n",
       " 243,\n",
       " 539,\n",
       " 441,\n",
       " 233,\n",
       " 311,\n",
       " 508,\n",
       " 852,\n",
       " 489,\n",
       " 568,\n",
       " 208,\n",
       " 828,\n",
       " 259,\n",
       " 389,\n",
       " 628,\n",
       " 870,\n",
       " 500,\n",
       " 541,\n",
       " 367,\n",
       " 930,\n",
       " 94,\n",
       " 817,\n",
       " 913,\n",
       " 236,\n",
       " 785,\n",
       " 701,\n",
       " 784,\n",
       " 113,\n",
       " 484,\n",
       " 902,\n",
       " 815,\n",
       " 634,\n",
       " 378,\n",
       " 697,\n",
       " 676,\n",
       " 861,\n",
       " 900,\n",
       " 151,\n",
       " 409,\n",
       " 668,\n",
       " 580,\n",
       " 771,\n",
       " 12,\n",
       " 21,\n",
       " 278,\n",
       " 590,\n",
       " 818,\n",
       " 39,\n",
       " 28,\n",
       " 699,\n",
       " 122,\n",
       " 882,\n",
       " 171,\n",
       " 888,\n",
       " 877,\n",
       " 306,\n",
       " 108,\n",
       " 412,\n",
       " 566,\n",
       " 188,\n",
       " 564,\n",
       " 503,\n",
       " 169,\n",
       " 404,\n",
       " 100,\n",
       " 212,\n",
       " 562,\n",
       " 872,\n",
       " 237,\n",
       " 633,\n",
       " 731,\n",
       " 487,\n",
       " 732,\n",
       " 901,\n",
       " 889,\n",
       " 225,\n",
       " 892,\n",
       " 426,\n",
       " 112,\n",
       " 285,\n",
       " 647,\n",
       " 758,\n",
       " 417,\n",
       " 656,\n",
       " 506,\n",
       " 678,\n",
       " 927,\n",
       " 528,\n",
       " 166,\n",
       " 454,\n",
       " 842,\n",
       " 296,\n",
       " 552,\n",
       " 554,\n",
       " 746,\n",
       " 227,\n",
       " 35,\n",
       " 504,\n",
       " 651,\n",
       " 70,\n",
       " 183,\n",
       " 337,\n",
       " 17,\n",
       " 1,\n",
       " 128,\n",
       " 42,\n",
       " 819,\n",
       " 142,\n",
       " 626,\n",
       " 155,\n",
       " 374,\n",
       " 266,\n",
       " 874,\n",
       " 880,\n",
       " 735,\n",
       " 649,\n",
       " 382,\n",
       " 326,\n",
       " 744,\n",
       " 63]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.344076</td>\n",
       "      <td>0.568386</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.699924</td>\n",
       "      <td>0.130034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.079683</td>\n",
       "      <td>0.323566</td>\n",
       "      <td>0.516857</td>\n",
       "      <td>0.601350</td>\n",
       "      <td>0.709679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.151721</td>\n",
       "      <td>0.822323</td>\n",
       "      <td>0.809330</td>\n",
       "      <td>0.503054</td>\n",
       "      <td>0.003494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.116009</td>\n",
       "      <td>0.409918</td>\n",
       "      <td>0.169117</td>\n",
       "      <td>0.165737</td>\n",
       "      <td>0.026960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.168565</td>\n",
       "      <td>0.102242</td>\n",
       "      <td>0.130126</td>\n",
       "      <td>0.704052</td>\n",
       "      <td>0.486274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.112260</td>\n",
       "      <td>0.674514</td>\n",
       "      <td>0.739262</td>\n",
       "      <td>0.308823</td>\n",
       "      <td>0.149770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.066878</td>\n",
       "      <td>0.946512</td>\n",
       "      <td>0.288020</td>\n",
       "      <td>0.856041</td>\n",
       "      <td>0.522778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.984733</td>\n",
       "      <td>0.266781</td>\n",
       "      <td>0.002233</td>\n",
       "      <td>0.046304</td>\n",
       "      <td>0.612792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.739914</td>\n",
       "      <td>0.116790</td>\n",
       "      <td>0.914125</td>\n",
       "      <td>0.228547</td>\n",
       "      <td>0.655344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063731</td>\n",
       "      <td>0.267333</td>\n",
       "      <td>0.129175</td>\n",
       "      <td>0.516174</td>\n",
       "      <td>0.322937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.386451</td>\n",
       "      <td>0.357931</td>\n",
       "      <td>0.687641</td>\n",
       "      <td>0.186848</td>\n",
       "      <td>0.433824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.258067</td>\n",
       "      <td>0.236856</td>\n",
       "      <td>0.100242</td>\n",
       "      <td>0.949300</td>\n",
       "      <td>0.355703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.247391</td>\n",
       "      <td>0.720474</td>\n",
       "      <td>0.319910</td>\n",
       "      <td>0.405189</td>\n",
       "      <td>0.837601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.142672</td>\n",
       "      <td>0.065772</td>\n",
       "      <td>0.685433</td>\n",
       "      <td>0.033473</td>\n",
       "      <td>0.445146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.951400</td>\n",
       "      <td>0.782969</td>\n",
       "      <td>0.499227</td>\n",
       "      <td>0.964570</td>\n",
       "      <td>0.018702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.720751</td>\n",
       "      <td>0.919507</td>\n",
       "      <td>0.460527</td>\n",
       "      <td>0.281957</td>\n",
       "      <td>0.369110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.339452</td>\n",
       "      <td>0.827686</td>\n",
       "      <td>0.985445</td>\n",
       "      <td>0.526358</td>\n",
       "      <td>0.014761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.030118</td>\n",
       "      <td>0.008089</td>\n",
       "      <td>0.674954</td>\n",
       "      <td>0.680407</td>\n",
       "      <td>0.073792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.193191</td>\n",
       "      <td>0.640424</td>\n",
       "      <td>0.228764</td>\n",
       "      <td>0.042799</td>\n",
       "      <td>0.626360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.778465</td>\n",
       "      <td>0.828103</td>\n",
       "      <td>0.268587</td>\n",
       "      <td>0.908529</td>\n",
       "      <td>0.103886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4\n",
       "0   0.344076  0.568386  0.651605  0.699924  0.130034\n",
       "1   0.079683  0.323566  0.516857  0.601350  0.709679\n",
       "2   0.151721  0.822323  0.809330  0.503054  0.003494\n",
       "3   0.116009  0.409918  0.169117  0.165737  0.026960\n",
       "4   0.168565  0.102242  0.130126  0.704052  0.486274\n",
       "5   0.112260  0.674514  0.739262  0.308823  0.149770\n",
       "6   0.066878  0.946512  0.288020  0.856041  0.522778\n",
       "7   0.984733  0.266781  0.002233  0.046304  0.612792\n",
       "8   0.739914  0.116790  0.914125  0.228547  0.655344\n",
       "9   0.063731  0.267333  0.129175  0.516174  0.322937\n",
       "10  0.386451  0.357931  0.687641  0.186848  0.433824\n",
       "11  0.258067  0.236856  0.100242  0.949300  0.355703\n",
       "12  0.247391  0.720474  0.319910  0.405189  0.837601\n",
       "13  0.142672  0.065772  0.685433  0.033473  0.445146\n",
       "14  0.951400  0.782969  0.499227  0.964570  0.018702\n",
       "15  0.720751  0.919507  0.460527  0.281957  0.369110\n",
       "16  0.339452  0.827686  0.985445  0.526358  0.014761\n",
       "17  0.030118  0.008089  0.674954  0.680407  0.073792\n",
       "18  0.193191  0.640424  0.228764  0.042799  0.626360\n",
       "19  0.778465  0.828103  0.268587  0.908529  0.103886"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([pd.DataFrame(np.random.random((10, 5))), pd.DataFrame(np.random.random((10, 5)))], axis=0).reset_index(drop=True)#.drop(columns='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col 1</th>\n",
       "      <th>col 2</th>\n",
       "      <th>col 3</th>\n",
       "      <th>col 4</th>\n",
       "      <th>order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>0.550838</td>\n",
       "      <td>0.718344</td>\n",
       "      <td>0.572114</td>\n",
       "      <td>0.960487</td>\n",
       "      <td>295.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>0.423839</td>\n",
       "      <td>0.923238</td>\n",
       "      <td>0.191413</td>\n",
       "      <td>0.359537</td>\n",
       "      <td>936.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>0.576540</td>\n",
       "      <td>0.074557</td>\n",
       "      <td>0.949364</td>\n",
       "      <td>0.288135</td>\n",
       "      <td>141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>256</th>\n",
       "      <td>0.209137</td>\n",
       "      <td>0.101296</td>\n",
       "      <td>0.627495</td>\n",
       "      <td>0.568705</td>\n",
       "      <td>255.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>0.851025</td>\n",
       "      <td>0.354406</td>\n",
       "      <td>0.742056</td>\n",
       "      <td>0.132330</td>\n",
       "      <td>399.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>650</th>\n",
       "      <td>0.924688</td>\n",
       "      <td>0.753968</td>\n",
       "      <td>0.455919</td>\n",
       "      <td>0.663938</td>\n",
       "      <td>649.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>383</th>\n",
       "      <td>0.970064</td>\n",
       "      <td>0.182723</td>\n",
       "      <td>0.765135</td>\n",
       "      <td>0.143405</td>\n",
       "      <td>382.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>0.476914</td>\n",
       "      <td>0.813547</td>\n",
       "      <td>0.171646</td>\n",
       "      <td>0.450530</td>\n",
       "      <td>326.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.862259</td>\n",
       "      <td>0.492404</td>\n",
       "      <td>0.293469</td>\n",
       "      <td>0.764378</td>\n",
       "      <td>744.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.074966</td>\n",
       "      <td>0.429759</td>\n",
       "      <td>0.747389</td>\n",
       "      <td>0.915532</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>658 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        col 1     col 2     col 3     col 4  order\n",
       "296  0.550838  0.718344  0.572114  0.960487  295.0\n",
       "937  0.423839  0.923238  0.191413  0.359537  936.0\n",
       "142  0.576540  0.074557  0.949364  0.288135  141.0\n",
       "256  0.209137  0.101296  0.627495  0.568705  255.0\n",
       "400  0.851025  0.354406  0.742056  0.132330  399.0\n",
       "..        ...       ...       ...       ...    ...\n",
       "650  0.924688  0.753968  0.455919  0.663938  649.0\n",
       "383  0.970064  0.182723  0.765135  0.143405  382.0\n",
       "327  0.476914  0.813547  0.171646  0.450530  326.0\n",
       "745  0.862259  0.492404  0.293469  0.764378  744.0\n",
       "63   0.074966  0.429759  0.747389  0.915532   63.0\n",
       "\n",
       "[658 rows x 5 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epochs.metadata.iloc[train.indices]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
